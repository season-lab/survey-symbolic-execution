% !TEX root = main.tex

\section{Constraint solving}
\label{se:constraint-solving}

Constraint satisfaction problems arise in many domains, including analysis, testing, and verification of software programs. Constraint solvers are decision procedures for problems expressed in logical formulas: for instance, the boolean satisfiability problem (also known as SAT) aims at determining whether there exists an interpretation of the symbols of a formula that makes it true. Although SAT is a well-known NP-complete problem, recent advances have moved the boundaries for what is intractable when it comes to practical applications~\cite{SMT-CACM11}. 

% linear arithmetic inequalities
Observe that some problems are more naturally described with languages that are more expressive than the one of boolean formulas with logical connectives. For this reason, satisfiability modulo theories (SMT) generalize the SAT problem with supporting theories to capture formulas involving, for instance, linear arithmetic and operations over \iffullver{arrays (see, e.g., Section~\ref{ss:fully-symbolic-memory}).}{arrays.} SMT solvers map the atoms in an SMT formula to fresh boolean variables: a SAT decision procedure checks the rewritten formula for satisfiability, and a theory solver checks the model generated by the SAT procedure. \mytempedit{In particular, SMT-compliant theory solvers are required to be able to: (i) work incrementally when checking for consistency as novel constraints are added, (ii) support backtracking, i.e., constraint removal, and (iii) provide explanations for inconsistent constraints~\cite{Abraham15}.}

\mytempedit{SMT solvers show a number of distinctive strengths. Their core algorithms are generic and can handle complex combinations of many individual constraints. Theories can be added and, more importantly, combined in arbitrary ways, e.g., to reason about arrays of strings. Decision procedures are not required to be carried out in isolation: in particular, they can profitably be combined to reduce the amount of time spent in heavier procedures, e.g., by solving linear problem parts first when tackling non-linear arithmetic formulas. Incomplete procedures are valuable too, as they can limit resorting to less efficient but complete procedures only when conclusive answers could not be produced. The combination of these factors allows modern SMT solver to tackle large problems that no single procedure could solve in isolation\footnote{We refer the interested reader to~\cite{BKM14} for an exhaustive introduction to SMT solving, and to~\cite{SC2} for a discussion of its distinctive strengths.}.}


In a symbolic executor, constraint solving plays a crucial role in checking the feasibility of a path, generating assignments to symbolic variables, and verifying assertions.
\mytempedit{Over the years, different solvers have been employed by symbolic executors, depending on the supported theories and the relative performance at the time. For instance, the STP~\cite{STP-CAV07,STP-TR07} solver has been employed in, e.g., {\sc EXE}~\cite{EXE-CCS06}, {\sc KLEE}~\cite{KLEE-OSDI08}, {\sc MineSweeper}~\cite{MineSweeper-BOTNET08}, and {\sc AEG}~\cite{AEG-NDSS11}, which all leverage its support for bit-vector and array theories. Other executors such as {\sc Java PathFinder}~\cite{PATHFINDER-ASE10} have complemented SMT solving with additional decision procedures, e.g., libraries for constraint programming~\cite{CHOCO} and heuristics to handle complex non-linear mathematical constraints~\cite{CORAL-NFM11}.

Recently, Z3~\cite{Z3-TACS08} has emerged as leading solution for SMT solving. Developed at Microsoft Research, Z3 offers cutting-edge performance and supports a large number of theories, including bit-vectors, arrays, quantifiers, uninterpreted functions, linear integer and real arithmetic, and non-linear arithmetic. 
%
Effective support for strings has been recently offered by Z3-str~\cite{ZZG-FSE13}, an extension of Z3 that makes it possible to treat string as a primitive type, allowing the solver to reason on common string operations such as concatenation, substring, and replacement.
%
Z3 is employed in most recently appeared symbolic executors such as {\sc Mayhem}~\cite{MAYHEM-SP12}, {\sc SAGE}~\cite{SAGE-QUEUE12}, and {\sc Angr}~\cite{ANGR-SSP16}. Due to the extensive number of supported theories in Z3, such executors typically do not to resort to additional decision procedures.
}

%The two most popular solvers used in symbolic executors are STP and Z3. STP~\cite{STP-CAV07,STP-TR07} is an SMT solver with bitvector and array theories initially developed at Stanford and employed in, e.g., {\sc EXE}~\cite{EXE-CCS06}, {\sc KLEE}~\cite{KLEE-OSDI08}, {\sc MineSweeper}~\cite{MineSweeper-BOTNET08}, and {\sc AEG}~\cite{AEG-NDSS11}. Z3~\cite{Z3-TACS08} is an SMT solver developed at Microsoft with support for nonlinear arithmetic, bitvector, and array theories, and is used in, e.g., {\sc Mayhem}~\cite{MAYHEM-SP12}, {\sc SAGE}~\cite{SAGE-QUEUE12}, and {\sc Angr}~\cite{ANGR-SSP16}. CVC3~\cite{CVC3-CAV07} is another SMT solver that supports theories for linear arithmetic, bitvectors, arrays, and quantifiers, and is employed in {\sc Java PathFinder}~\cite{PATHFINDER-ASE10} along with CHOCO~\cite{CHOCO} for integer/real constraints and CORAL~\cite{CORAL-NFM11} for complex mathematical constraints. Modern symbolic executors can typically choose between different underlying solvers through a common API, and also resort to a native interface to a specific solver for better performance.

%only for efficiency reasons.

%For instance, many solvers have the development of ~\cite{PATHFINDER-ASE10} can use a large number of SMT solvers, including Yices, 
%~\cite{YICES-CAV06} is an incremental solver with support for rational and integer linear arithmetic, bitvectors, and arrays, and was originally used in 
%In Table~\ref{tab:solvers} we report a number of constraint solving tools used in popular symbolic execution engines.

\iffalse
\begin{figure}[ht]
  \centering
  \begin{adjustbox}{width=1\columnwidth}
  \begin{small}
  \begin{tabular}{| l | p{8cm} | p{4cm} |}
    \hline      
    Constraint solver & Description & Used in  \\ \hline\hline
    \cite{STP-TR07} & SMT + bitvectors, arrays & ~\cite{EXE-CCS06,KLEE-OSDI08,MineSweeper-BOTNET08,AEG-NDSS11}, SPF? \\
    \cite{Z3-TACS08} & SMT + (non)linear arithmetic, bitvectors, arrays & ~\cite{FIRMALICE-NDSS15,MAYHEM-SP12}, SAGE \\
    \cite{CVC3-CAV07} & SMT + linear arithmetic, bitvectors, arrays, quantifiers & SPF \\
    \cite{YICES-CAV06} & SMT + rational and integer linear arithmetic, bitvectors, arrays & originally in SPF\\
    \hline  
  \end{tabular}
  \end{small}
  \end{adjustbox}
  \caption{List of constraint solvers.}
  \label{tab:solvers}
\end{figure}
\fi

% feasibility or applicability? TODO
However, despite the significant advances observed over the past few years -- which also made symbolic execution practical in the first place~\cite{CS-CACM13} -- constraint solving remains one of the main obstacles to the scalability of symbolic execution engines, \mytempedit{and also hinders its feasibility in the face of constraints that involve expensive theories (e.g., non-linear arithmetic) or opaque library calls.}

%\subsection{Optimization Techniques}
%\label{ss:constraint-opt}

% handling or skipping over
In the remainder of this section, we address different techniques to extend the range of programs \iffullver{that can be handled by}{amenable to} symbolic execution and to optimize the performance of constraint solving. Prominent approaches consist in: (i) reducing the size and complexity of the constraints to check, (ii) unburdening the solver by, e.g., resorting to constraint solution caching, deferring of \iffullver{constraint solver queries}{solver queries}, or concretization, \mytempedit{and (iii) augmenting symbolic execution with techniques aimed at handling constraints that are problematic for the underlying decision procedure. We conclude the section by pointing out potential research directions to improve support for non-linear arithmetic}.

%: (i) {\em constraint reduction} techniques aim at simplifying constraints fed to a solver by rewriting them into a shorter form: (ii) techniques for {\em reuse of constraint solutions} explore the space-time trade-off of retrieving previously computed query results rather than repeating expensive satisfiability checks.

\myparagraph{Constraint Reduction} 
A common optimization approach followed by both solvers and symbolic executors is to reduce constraints into simpler forms. For example, the {\em expression rewriting} optimization can apply classical techniques from optimizing compilers such as constant folding, strength reduction, and simplification of linear expressions (see, e.g., {\sc KLEE}~\cite{KLEE-OSDI08}).

{\sc EXE}~\cite{EXE-CCS06} introduces a {\em constraint independence} optimization that exploits the fact that a set of constraints can frequently be divided into multiple independent subsets of constraints. This optimization interacts well with query result caching strategies, and offers an additional advantage when an engine asks the solver about the satisfiability of a specific constraint, as it removes irrelevant constraints from the query. In fact, independent branches, which tend to be frequent in real programs, could lead to unnecessary constraints that would get quickly accumulated.

Another fact that can be exploited by reduction techniques is that the natural structure of programs can lead to the introduction of more specific constraints for some variables as the execution proceeds. Since path conditions are generated by conjoining new terms to an existing sequence, it might become possible to rewrite and optimize existing constraints. For instance, adding an equality constraint of the form $x:=5$ enables not only the simplification to true of other constraints over the value of the variable (e.g., $x>0$), but also the substitution of the symbol $x$ with the associated concrete value in the other subsequent constraints involving it. The latter optimization is also known as {\em implied value concretization} and, for instance, it is employed by {\sc KLEE}~\cite{KLEE-OSDI08}.

In a similar spirit, {\sc \stwoe}~\cite{CKC-TOCS12} introduces a bitfield-theory expression simplifier to replace with concrete values parts of a symbolic variable that bit operations mask away. For instance, for any 8-bit symbolic value $v$, the most significant bit in the value of expression $v\,|\,10000000_2$ is always 1. The simplifier can propagate information across the tree representation of an expression, and if each bit in its value can be determined, the expression is replaced with the corresponding constant.
 
%path conditions in a symbolic executor are typically generated by conjoining a new term to an existing (and possibly satisfiable) sequence of constraints. As the exploration proceeds, the natural structure of programs means that constraints might become more specific for some variables, and constraints can be rewritten accordingly. 

%\subsubsection{Reuse of Constraint Solutions}
%\label{ss:constraint-reuse}

%\subsection{Unburdening the Constraint Solver} 
%\label{ss:solver-unburdening}

\myparagraph{Reuse of Constraint Solutions} 
The idea of reusing previously computed results to speed up constraint solving can be particularly effective in the setting of a symbolic executor, especially when combined with other techniques such as constraint independence optimization. Most reuse approaches for constraint solving are currently based on semantic or syntactic equivalence of the constraints.

{\sc EXE}~\cite{EXE-CCS06} caches the results of constraint solutions and satisfiability queries in order to reduce as much as possible the need for calling the solver. A cache is handled by a server process that can receive queries from multiple parallel instances of the execution engine, each exploring a different program state.

{\sc KLEE}~\cite{KLEE-OSDI08} implements an incremental optimization strategy called {\em counterexample caching}. Using a cache, constraint sets are mapped to concrete variable assignments, or to a special null value when a constraint set is unsatisfiable. When an unsatisfiable set in the cache is a subset for a given constraint set $S$, $S$ is deemed unsatisfiable as well. Conversely, when the cache contains a solution for a superset of $S$, the solution trivially satisfies $S$ too. Finally, when the cache contains a solution for one or more subsets of $S$, the algorithm tries substituting in all the solutions to check whether a satisfying solution for $S$ can be found.

{\em Memoized symbolic execution}~\cite{MEMO-ISSTA12} is motivated by the observation that symbolic execution often results in re-running largely similar sub-problems, e.g., finding a bug, fixing it, and then testing the program again to check if the fix was effective. The taken choices during path exploration are compactly encoded in a trie-based data structure, opening up the possibility to reuse previously computed results in successive runs.

The Green framework~\cite{GREEN-FSE12} explores constraint solution reuse across runs of not only the same program, but also similar programs, different programs, and different analyses. Constraints are distilled into their essential parts through a {\em slicing} transformation and represented in a canonical form to achieve good reuse, even within a single analysis run. ~\cite{JGY-ISSTA15} presents an extension to the framework that exploits logical implication relations between constraints to support constraint reuse and faster execution times.

%\subsection{Other Optimizations in Symbolic Executors}
%\subsection{Reducing the Symbolic Executor's Pressure on Constraint Solvers}
%\label{ss:reducing-constraint-solver-pressure}

%In this section we present a number of other optimizations that become possible in the setting of a symbolic executor to reduce the time spent in the constraint solver.

\myparagraph{Lazy Constraints}
\cite{UCKLEE-USEC15} adopts a timeout approach for constraint solver queries. In their initial experiments, the authors traced most timeouts to symbolic division and remainder operations, with the worst cases occurring when an unsigned remainder operation had a symbolic value in the denominator.
They thus implemented a solution that works as follow: when the executor encounters a branch statement involving an expensive symbolic operation, it will take both the true and false branches and add a {\em lazy} constraint on the result of the expensive operation to the path conditions. When the exploration reaches a state that satisfies some goal (e.g., an error is found), the algorithm will check for the feasibility of the path, and suppress it if deemed as unreachable in a real execution.

Compared to the {\em eager} approach of checking the feasibility of a branch as encountered (Section~\ref{ss:unrealizable-paths}), a lazy strategy may lead to a larger number of active states, and in turn to more solver queries. However, the authors report that the delayed queries are in many cases more efficient than their eager counterparts: the path constraints added after a lazy constraint can in fact narrow down the solution space for the solver.

\begin{figure}[t]
  \begin{center}
  \begin{subfigure}{.4\textwidth}
    \vspace{0mm}
    \begin{lstlisting}[basicstyle=\ttfamily\scriptsize]
1. int non_linear(int v) {
2.    return (v*v) % 50;
3. }
    \end{lstlisting}
    \vspace{8.5mm}
    %\caption{}
  \end{subfigure}%
    \begin{subfigure}{.4\textwidth}
    %\vspace{0mm}
    \begin{lstlisting}[basicstyle=\ttfamily\scriptsize]
4. void test(int x, int y) {
5.    z = non_linear(y);
6.    if (z == x) {
7.      if (x > y + 10) ERROR;  
8.    }
9. }
    \end{lstlisting}
    %\vspace{3.5mm}
    %\caption{}
  \end{subfigure}%
  \end{center}
  \vspace{-3.5mm}
  \caption{Example with non-linear constraints.}
  \label{fi:non-linear-constraints}
\end{figure}


\myparagraph{Concretization}
\cite{CS-CACM13} discusses limitations of classical symbolic execution in the presence of formulas that constraint solvers cannot solve, at least not efficiently.

\boxedexample{In the code fragment of Figure~\ref{fi:non-linear-constraints}, the engine stores a non-linear constraint of the form $\alpha_x = (\alpha_y*\alpha_y)\,\%\,50$ for the $true$ branch at line 6. A solver that does not support non-linear arithmetic fails to generate any input for the program.}

\noindent A concolic executor generates some random input for the program and executes it both concretely and symbolically: a possible value from the concrete execution can be used for a symbolic operand involved in a formula that is inherently hard for the solver, albeit at the cost of sacrificing soundness in the exploration. For instance, in the presence of three nested branches with only one being non-linear, {\sc DART}~\cite{DART-PLDI05} starts from a random valid input for the function, and then alters it when symbolically exploring the two linear branches. The work resorts to concretization also to avoid performing expensive or imprecise alias analysis on pointers. % with only one of them being

% suggests to
To partially overcome the incompleteness due to concretization,~\cite{PRV-ISSTA11} suggests \mytempedit{{\em mixed concrete-symbolic solving}, which} considers {\em all} the path constraints collectable over a path before binding one or more symbols to specific concrete values. Indeed, {\sc DART}~\cite{DART-PLDI05} concretizes symbols based on the path constraints collected up to a target branch. In this manner, a constraint contained in a subsequent branch in the same path is not considered and it may be not satisfiable due to already concretized symbols. If this happen, {\sc DART} restarts the execution with different random concrete values, hoping to be able to satisfy the subsequent branch. The approach presented in~\cite{PRV-ISSTA11} requires instead to detect {\em solvable} constraints along a full path and to delay concretization as much as possible.

\mytempedit{\myparagraph{Handling Problematic Constraints}
Strong SMT solvers allow executors to handle more path constraints directly, reducing the need to resort to concretization. This also results in a lower risk to incur a {\em blind commitment} to concrete values~\cite{DA-FSE14}, which happens when the under-approximation of path conditions from a random choice of concrete values for some variables results in an arbitrary restriction of the search space. Unfortunately, some constraints remain prohibitive for SMT solvers: for instance, non-linear integer arithmetic is undecidable in general; also, a branch condition might contain calls to opaque library methods such as trigonometric functions that would require special extensions to the solver to reason about.

\cite{DA-FSE14} proposes a {\em concolic walk} algorithm that can tackle control-flow dependencies involving non-linear arithmetic and library calls. The algorithm treats assignments of values to variables as a valuation space: the solutions of the linear constraints define a polytope that can be walked heuristically, while the remaining constraints are assigned with a fitness function measuring how close a valuation point is to matching the constraint. An adaptive search is performed on the polytope as points are picked on it and non-linear constraints evaluated on them. Compared to mixed concrete-symbolic solving~\cite{PRV-ISSTA11}, both techniques seek to avoid blind commitment. However, concolic walk does not rely on the solver for obtaining all the concrete inputs needed to evaluate complex constraints, and implements search heuristics that guide the walk on the polytope towards promising regions.

% Symcretic execution
\cite{DA-ASE14} describes {\em symcretic} exploration, a novel combination of symbolic backward execution (SBE) (see Section~\ref{se:executors}) and concrete forward symbolic execution. The main idea is to divide exploration into two phases. In the first phase, SBE is performed from a target point and a trace is collected for each followed path. If some {\em problematic} constraints are met during the backward exploration, then the engine marks them as {\em potentially} satisfiable by adding a special trace event and continues its reversed traversal. When an entry point of the program is reached by {\em symcretic} in one of the followed paths, then the second phase is started. The engine concretely evaluates the collected trace, trying to satisfy any constraint that have been marked as problematic during the first phase. This is done using a heuristic search, such as concolic walk~\cite{DA-FSE14}, which determines how close the branch conditions are to being satisfied and alters the concrete inputs to move closer to a full solution. A benefit of {\em symcretic} with respect to traditional concolic execution is that it can avoid exploring irrelevant paths. For instance, if an {\tt assert} statement is guarded by a branch condition which can be proved to unsatisfiable, then there is no need to take into account all the other constraints along the path toward the entry point to declare the target point as unreachable. Indeed, a traditional concolic executor reasons over all the constraints along a path with top-down approach, making it hard to recognize the unreachability of a target statement due to some constraints deep into the path.
}

% , i.e., polynomial constraints over variables
\mytempedit{\myparagraph{Symbolic Computation} Although the satisfiability problem is known to be NP-hard already for SAT, the mathematical developments over the past decades have produced several practically applicable methods to solve arithmetic formulas. In particular, studies in the area of {\em symbolic computation}, also known as computer algebra, have produced powerful methods such as Gr\"{o}bner bases for solving systems of polynomial constraints, cylindrical algebraic decomposition for real algebraic geometry, and virtual substitution for non-linear real arithmetic formulas.

% handling complex Boolean constraints and; quantifier-free non-linear
While SMT solvers have proven to be very efficient at combining theories and heuristics when processing complex expressions, they make use of symbolic computation techniques only to a little extent, and their support for non-linear real and integer arithmetic is still in its infancy~\cite{Abraham15}. To the best of our knowledge, only Z3 and SMT-RAT~\cite{SMTRAT15} provide support to reason about them both.

Using symbolic computation techniques as theory plugins for SMT solvers is a promising symbiosis, as they provide powerful procedures for solving conjunctions of arithmetic constraints~\cite{Abraham15}. The realisation of this idea is hindered by the fact that available implementations of such procedures do not comply with the incremental, backtracking and explanation of inconsistencies properties expected of SMT-compliant theory solvers. One interesting project to look at is SC\textsuperscript{2}~\cite{SC2}, whose goal is to create a new community aiming at bridging the gap between symbolic computation and satisfiability checking, combining the strengths of both worlds in order to pursue problems currently beyond their individual reach.

Further opportunities to increase efficiency when tackling non-linear expressions might be found in the recent advances in {\em symbolic-numeric computation}~\cite{HandbookOfCompAlgebra}. In particular, these techniques aim at developing efficient polynomial solvers by combining numerical algorithms, which are very efficient in approximating local solutions but lack a global view, with the guarantees from symbolic computation techniques. This hybrid techniques can extend the domain of efficiently solvable problems, and thus be of interest for non-linear constraints from symbolic execution.
}
%\myparagraph{Memory Page Size}
%In {\sc \stwoe}~\cite{CKC-TOCS12}, when a symbolic pointer is dereferenced, the engine determines which memory pages are referenced by it and passes their contents to the solver. As large page sizes can overwhelm the solver, {\sc \stwoe} uses small pages of configurable size rather than the default 4KB pages. The authors report significant performance benefits from using pages of smaller size.


